\documentclass[addpoints,12pt]{exam}
\usepackage{amsmath, amssymb}
\linespread{1.1}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{multirow}



%-------------------DON'T CHANGE---------------------%
%The following is needed to prevent a conflict between knitr and the exam class involving the package ``framed.''
<<cache=FALSE,include=FALSE,purl=FALSE>>= 
knit_hooks$set(document=function(x){ 
  sub('\\usepackage{framed}', '', x, fixed=TRUE) 
}) 
@ 


%This keeps images from being too big, centers them, and makes sure we use pdf images
<<cache=FALSE,include=FALSE,purl=FALSE>>= 
opts_chunk$set(fig.width=4, fig.height=4, fig.align='center',dev='pdf')
@


%Change the default width of the output to fit within the solution boxes
<<cache=FALSE,include=FALSE,purl=FALSE>>= 
options(width = 60)
@
%-------------------DON'T CHANGE---------------------%


%To include the answers use:
%  pdflatex "\def\showanswers{1} \input{thisfile.tex}"
%\ifdefined\showanswers
  \printanswers
%\else
 % \noprintanswers
%\fi

\title{Extra Credit Problem}
\author{Econ 103}
\date{}
\begin{document}
\maketitle

\section*{Regression with R}
\begin{questions}

\question This question is based on the dataset on child test scores and mother characteristics. You can download the data with the following code:

<<>>=
data.url <- 'http://www.ditraglia.com/econ103/child_test_data.csv'
data <- read.csv(data.url)
head(data)
attach(data)
@
\vspace{0.2in}
The columns contained in this dataset are as follows:
\begin{table}[h]
\centering
	\begin{tabular}{ll}
		Variable Name & Description\\
		\hline
		\texttt{kid.score}& Child's Test Score at Age 3\\
		\texttt{mom.age}&Age of Mother at Birth of Child\\
		\texttt{mom.hs}& Mother Completed High School? (1 = Yes)\\
		\texttt{mom.iq}& Mother's IQ Score
	\end{tabular}
\end{table}
\newpage
	\begin{parts}
		\part Run a regression of \texttt{kid.score} on \texttt{mom.age}. Plot both the data and the fitted regression line, making sure to label the axes  (Check R tutorial 3). \underline{Interpret the results}. 
    \begin{solution}
<<message=FALSE, warning=FALSE>>=
reg1 <- lm(kid.score ~ mom.age)
summary(reg1)
plot(mom.age, kid.score, pch = 20, xlab = 'Age of Mother at Birth', 
     ylab = 'Child Test Score at Age 3')
coefficients(reg1)
intercept <- coef(reg1)[1]
slope <- coef(reg1)[2]
abline(a = intercept, b = slope)
@
Our model suggests that the children of mothers who were older when they gave birth tend to score higher. In particular, comparing two children whose mothers' age at birth differed by one year, we would predict that the child of the older mother will score, on average, 0.7 points higher. The standard error associated with the estimate, however, is fairly large. An approximate 95\% CI would just barely include zero. Nevertheless, this result is suggestive that the children of older mothers do better on the test. This would seem to suggest that women should wait to have children until they are as old as possible. However, for this advice to truly be valid, it would have to be the case that being older when you give birth \emph{caused} your child to have higher test scores. This seems unlikely, since there are many possible confounders here.
    \end{solution}
		\part Augment your model from part (a) by allowing a different intercept for children whose mother completed high school. Interpret your results and compare them to those you got in part (a).
    \begin{solution}
<<>>=
reg2 <- lm(kid.score ~ mom.hs + mom.age)
summary(reg2)
coef(reg2)
@
By adding a dummy variable that equals one if a child's mother completed high school, we have controlled for one of the possible confounders from above: mother's level of education. We have done this by allowing the regression line to have a different intercept depending on mother's education. Comparing two children whose mothers are of the same age but only one whom attended high school, we predict that the child of the better educated mother will score, on average, 11.3 points higher. The standard error associated with this estimate is quite small, yielding a 95\% CI that is is nowhere near zero. We have strong evidence of a large effect from mother's education level. In contrast, once we've controlled from mother's education, the estimated effect of \texttt{mom.age} falls substantially while the associated standard error stays the same. This results in an approximate 95\% CI that includes many negative values. After controlling for mother's education, there is much less evidence to suggest that older mothers have higher-scoring children.     
\end{solution}
		\part Now allow different slopes as well as intercepts for each group (those whose mother completed high school and those whose mother did not).  Interpret your results. 
\begin{solution}
<<>>=
reg3 <- lm(kid.score ~ mom.hs + mom.age + mom.hs:mom.age)
summary(reg3)
coef(reg3)
intercept.no.hs <- coef(reg3)[1]
intercept.hs <- coef(reg3)[1] + coef(reg3)[2]
slope.no.hs <- coef(reg3)[3]
slope.hs <- coef(reg3)[3] + coef(reg3)[4]
@
When we allow for different slopes as well as intercepts, by adding an \emph{interaction} between \texttt{mom.hs} and \texttt{mom.hs}, namely \texttt{mom.hs:mom.age}, we find very different results depending on mother's education. (There is strong evidence that we should allow for different slopes, since the approximate 95\% CI for the interaction does not include zero.)  For children whose mothers attended high school, there is a \emph{positive} relationship between mother's age at birth and child's test score. For children whose mothers did not attend high school, the relationship is \emph{negative}. For children whose mothers were 18 then they gave birth, there is essentially \emph{no} impact from mother's education level. As age of mother at birth increases, the impact of mother's education widens. 
\end{solution}
		\part Lastly, include mother's IQ as additional variable to the regression done in (c). Would you prefer to include mother's IQ instead of leaving it out of the regression? Compare regression results in (c) and (d). 
\begin{solution}
Mother's IQ variable is highly statistically significant. Given everything else as fixed, we predict that the child of a mother whose IQ is 1 point higher will score, on average, 1.57 points higher. After controlling for mother's IQ, mother's high school dummy and mother's age variable are not statistically significant. However, the interaction between the high school dummy and age variable still matters in the regression. Given that the mother's IQ variable has explanatory power, I would prefer to include this variable in the regression. Also, comparing adjusted R-squared and residual standard error of two regressions, regression in (d) fits the data better.
<<>>=
reg4 <- lm(kid.score ~ mom.hs + mom.age + mom.hs:mom.age + mom.iq)
summary(reg4)
@
\end{solution}
	\end{parts}
	

	

\end{questions}















\end{document}